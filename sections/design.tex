\documentclass[../main.tex]{subfiles}
\externaldocument{introduction}
\graphicspath{{\subfix{../images/}}}

\begin{document}

\begin{newrequirements}
    \begin{todolist}
        \item detailed design specifications of the 
            hardware and software to meet the 
            functional requirements and the 
            practical design constraints 

        \item use circuit diagrams, logic diagrams, 
            block diagrams, flow charts, class 
            diagrams and/or sequence diagrams 

        \item detailed justification of design 
            choices 

        \item highlight the novel design aspects 

        \item evaluate the effect of design choices 
            on your system quality attributes 

        \item not required to include all of these 
            sub-sections, instead you need to 
            decide how to best communicate your 
            solution’s design
    \end{todolist}
\end{newrequirements}

\subsection{Overview}

% \begin{newrequirements}
%     \begin{todolist}
%         \item a simple one or two paragraphs giving a 
%             birds-eye view of the solution 

%         \item very generic so that even a layman will 
%             be able to comprehend the scope of your 
%             work 

%         \item a high level architecture diagram of 
%             the proposed solution. The diagram 
%             should show how your solutions is 
%             decomposed and organized into 
%             components. Can be a Block Diagram or 
%             Illustrative Block diagram in which 
%             some components/blocks can be 
%             illustrations/images of the actual 
%             component. 

%         \item Describe the role and the interfaces of 
%             key components of your high level 
%             architecture. 

%         \item Discuss the key interactions between 
%             the identified components. 

%         \item While one Block diagram can be used to 
%             show hardware components/connectivity, 
%             another Block diagram or Flow chart can 
%             be used to do the same for the software 
%             aspect of the project. 
                
%     \end{todolist}
% \end{newrequirements}

The overview of the proposed solution is depicted in 
\cref{fig:solution-overview}. 
The hardware components consist of an \anafi drone,
a Raspberry Pi with an external battery, and a Wi-Fi
dongle. The built-in camera of the drone is used to
take pictures of the targets and the Wi-Fi dongle
is used to communicate with the command and control
system, which sends high-level commands whenever the
connection is present. An object detection model trained
using RoboFlow detects and identifies the targets in the
pictures. In addition, a \gls{drl} agent is trained 
in a cyber-physical simulator called Sphinx to
visit virtual targets having the same mobility pattern as the
real ones.
This finished model is loaded into the Raspberry Pi that acts
as an onboard computer to the \anafi drone and instructs
it where to move to cover the targets in a minimum amount
of time.

The following subsections will
explain in more detail why this solution is chosen
and what the integral components are.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.9\textwidth]{solution-diagram}
	\caption{A general overview of the solution.}
	\label{fig:solution-overview}
\end{figure}

\subsection{High level architecture}

\Cref{fig:arch-fig} shows a high-level architecture 
of the complete working system, in which a group 
of connected adapters and devices are combined into 
a single functional system. 
The architecture is composed of three sections namely
interfacing, controlling, and targets. 
The interfacing section contains the drone that 
will handle the onboard computer, its power source, 
and the connection adapters. 
In the controlling part, a personal computer 
will be responsible for contacting the onboard computer 
to adjust settings, execute scripts, and get 
live updates and results. 
Finally, there will be multiple moving targets 
in the target section. For example, 
\gls{rc} cars are controlled manually and moving in 
a specific mobility pattern with varying directions 
and destinations. 
In the next section, hardware and software components 
will be presented in a more detailed manner.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.9\textwidth]{high-level-arch.png}
    \caption{The high-level architecture of the overall system.}
    \label{fig:arch-fig}
\end{figure}

\subsection{Hardware/software used}

\begin{newrequirements}
    \begin{todolist}
    \item Describe each hardware component and how it works 
        and the \textbf{scientific principles of its 
        inner working}.
    \end{todolist}
\end{newrequirements}

\subsubsection{Software}

There are three primary categories of software 
depending on the usage: simulation, training, 
and application, and they are listed in \cref{tab:software-used}. The first part will focus on 
simulating the environment, testing the models, 
and flight control. Before discussing the software 
to be used, we have selected Ubuntu 18.04 (Bionic Beaver) 
as an operating system for several reasons. 
One key reason is that in addition to
still being supported, it is compatible with the 
Parrot's Olympe and Sphinx programs, which are only 
supported on limited distributions and operating systems.
Another reason is that it is a lite \textsc{os} 
and can be installed on the onboard computer that 
will be attached to the drone. For the simulation part, 
using Sphinx and Gazebo software is very helpful
to visualize the environment, control the drone, 
and apply the \gls{drl} model. 

\begin{table}[p]
    \centering
    \caption{Software used in the project.}
    \label{tab:software-used}  
    \begin{tabular}{ p{3cm} p{3cm} p{6cm} }
        \toprule
        \textit{Software} 
            & \textit{Logo} 
                & \textit{Justification} \\ 

        \midrule

        Parrot Olympe  
            & 
            \raisebox{-0.7\height}
            {\includegraphics[width=2.7cm]
            {parrot.png}}
                & A controller for the Parrot \anafi 
                drone. It makes controlling 
                the drone possible 
                using a Python script \\
                \addlinespace

        Parrot Sphinx  
            & 
            \raisebox{-0.7\height}
            {\includegraphics[width=2.7cm]
            {parrot.png}}
                & A simulator for the Parrot \anafi drone.
                It loads the Parrot's drone firmware 
                in the simulation environment.
                It is largely based on Gazebo. \\
                \addlinespace

        Jupyter Notebook  
            & 
            \raisebox{-0.9\height}
            {\includegraphics[width=2.5cm]{jupyter.png}}
                & A web application for writing, testing 
                and sharing of code. It is free 
                and does not require internet access like 
                the Google Colab. It is used heavily 
                in this project to experiment with new 
                ideas in the Sphinx simulation. \\ 
                \addlinespace

        Zbar
            & 
            \raisebox{-0.9\height}
            {\includegraphics[width=1.8cm]{zbar.png}}
                & A software suite capable of reading widely-used
                symbologies including QR code. Its Python binding
                Pyzbar is used as a library in this project to
                detect the QR codes of the targets. \\ 
                \addlinespace

        \bottomrule
    \end{tabular}
\end{table}

Sphinx is a simulation 
tool built on top of Gazebo 
to run the Parrot's drone firmware on 
personal computers, which comes with helpful 
features for simulation such as visualizing flight 
data at runtime, running the \gls{uav} remotely, 
and executing scripts with the command line. 
Gazebo is a robot \textsc{gui} simulation 
which simulates the visual and physical surrounding 
of drones and custom 3D objects. 
\Cref{fig:gazebo} shows how the Sphinx 
program looks like. 

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.9\textwidth]{gazebo.png}
    \caption{The Sphinx program that runs on top of Gazebo.}
    \label{fig:gazebo}
\end{figure}

For the object detection model, the Pyzbar library was used to detect
the QR codes of the targets.
It has an accuracy of up to 90\% in good conditions but can be as
low as 30\% when the QR code is damaged due to an error in photo
capturing and processing~\cite{dynamsoft}.

For the application software, Parrot Olympe 
was used to send commands to the physical as well as 
the simulated drone and control the flight trip and 
how the drone moves. Parrot Olympe uses Python 
controller programming interface for Parrot drones 
which makes controlling simple and easy using a 
Python script. Moreover, Olympe allows us to read
sensor data, such as the \gls{gps} fixes and camera feed, 
from the \anafi
drone. This will make it possible to build a user interface
on the control and command station
shown in \cref{fig:ui-prototype} to monitor 
the progress of the drone
when it is autonomously executing the task visitation
mission.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.9\textwidth]{ui-prototype}
    \caption{An example of a user interface that will be built
                using sensor data coming from the \anafi drone.}
    \label{fig:ui-prototype}
\end{figure}

\subsubsection{Hardware}

The main core of the hardware part is the drone, 
which will be the Parrot \anafi.
\Cref{tab:hardware-used} lists the hardware components
used in this project and their justifications. 
The second important device is the Raspberry Pi. It
acts as an onboard computer and is used in this project
mainly to facilitate the low-level control of the drone
by sending frequent control commands to the drone
in a certain direction or keep hovering.
The choice of action is determined by the \gls{drl}
model that will be installed in it.
Hence, the tasks of the Raspberry Pi are:

\begin{table}[p]
    \centering
    \caption{Hardware used in the project.}
    \label{tab:hardware-used}  
    \begin{tabular}{ p{4cm} p{3cm} p{6cm} }
        \toprule
        \textit{Hardware} 
            & \textit{Picture} 
                & \textit{Justification} \\ 
        
        \midrule

        Parrot \anafi Drone  
            & \begin{minipage}{.1\textwidth}
                \includegraphics[width=30mm, height=20mm]{anafi.png}
        \end{minipage} 
                & Available in the university, can be 
                controlled easily 
                with simple Python script, 
                4K-high resolution camera.  \\ 
                \addlinespace

        Raspberry Pi 4  
            & \begin{minipage}{.0\textwidth}
                \includegraphics[width=30mm, height=20mm]{raspberry.jpg}
        \end{minipage} 
                & Specifications are enough for our 
                application, support Wi-Fi and its 
                small size and weight is an advantage.\\ 
                \addlinespace

        \textsc{rpi} \textsc{upsp}ack \textsc{v}3 with 
        \SI{4000}{\milli\ampere\hour} 
        lithium Battery  
            & \begin{minipage}{.1\textwidth}
                \includegraphics[width=30mm, height=35mm]{RPI.jpg}
        \end{minipage}  
                & Support up to 4 hours which is more 
                than enough , the board got an \textsc{led} 
                indicator for charging level also the 
                weight and shape is an advantage.  \\ 
                \addlinespace

        Wireless N Nano \textsc{usb} Adapter  
            & \begin{minipage}{.1\textwidth}
                \includegraphics[width=28mm, height=28mm]{dongle.jpg}
        \end{minipage} 
                & Cheap and do its job, good coverage 
                range.  \\ 
                \addlinespace

   Laptop 
            & \begin{minipage}{.1\textwidth}
                \includegraphics[width=30mm, height=30mm]{laptop.png}
        \end{minipage} 
                & Any laptop with good WiFi interface 
                card will be enough for our case. \\ 
                \addlinespace

        \bottomrule
    \end{tabular}
\end{table}    

\begin{enumerate}
    \item connecting to the drone's access point 
        using a Wi-Fi interface,
    \item controlling the drone 
        by executing Olympe to send low-level control signals 
        and to receive sensory data,
    \item applying the \gls{drl} model supported by 
        the command and control system, and
    \item receiving high-level commands and 
        sending data to the command and control system.
\end{enumerate}
 
The Parrot \anafi drone is connected 
to the Raspberry Pi, which is the onboard computer,
using both devices' internal 
\SI{2.4}{\giga\hertz}
Wi-Fi interfaces. 
Firstly, we add the \anafi drone's access point 
to the saved devices list in the Raspberry Pi.
Once the Raspberry Pi boots up, it automatically keeps 
searching for the access point and connects 
to it once it is available.

For the connection between the command and control system 
and the Raspberry Pi, 
the Raspberry Pi will use a 
\SI[per-mode=symbol,per-symbol=p]{300}{MBps} 
Wi-Fi adapter dongle connected to 
its \textsc{usb} port. 
This will allow it to create an access point
to which the command and control device 
will connect and by which the Raspberry Pi can be controlled.
This control of the onboard computer 
is done through the Secure Shell (\textsc{ssh})
protocol or the Virtual Network Computing (\textsc{vnc})
if the graphical interface is needed. 

Regarding the power source for the Raspberry Pi, 
we thought of taking power directly from the 
drone's battery, but, after some research, we found 
that the \anafi drone's  
socket is somehow different. It is also challenging 
and the drone battery is susceptible to shutting down 
immediately if the voltage reaches less than 3.0 Volt. 
So, we did not want to take the risk and used a 
lithium battery with a power board called 
\textsc{upsp}ack Standard Power Supply attached to 
the main Raspberry Pi board. It includes a 
\SI{4000}{\milli\ampere\hour}
lithium battery, which provides enough power 
and time for our application.

\subsection{Hardware design}

\begin{newrequirements}
    \begin{todolist}
        \item For major hardware subsystems in your 
            design, you must present the theory 
            behind the different technological 
            approaches, the tradeoffs associated 
            with each approach, and your 
            justification for selecting a 
            particular approach. For instance, 
            selection of a particular 
            microcontroller for your design; what 
            were the main factors that contributed 
            to this specific choice. For example, 
            you may choose between Arduino, 
            MC68HCxxx, BasicStamp, and PIC18Fxx and 
            you have decided to use PIC18F47 due 
            to: 

        \begin{todolist}
        \item its programming compatibility with C 

        \item its low cost 

        \item its development platform availability 

        \item ability to input analog signals 
        \end{todolist}

        \item To document the design of the hardware 
        components you can use as many of the 
        following as possible: 

        \begin{todolist}
        \item Circuit Diagram (Showing actual circuit 
        diagram with all the components used) 

        \item Connectivity diagram for modular 
        hardware. 

        \item Logic Diagrams (Showing logic flow with 
        respect to signals/numbers) 

        \item Functional Diagrams (showing subsets of 
        the circuit as functional blocks) 

        \item State Diagrams (to explain the 
        sequential logic flow) 

        \item Any other drawings to communicate your 
        design 
        \end{todolist}

        \item Organize the content of this section 
        using appropriate subsections. It is 
        recommended to have a sub-section of 
        each of the recommended artifacts 
        listed above. 

    \end{todolist}
\end{newrequirements}

\lipsum[4]

\subsection{Software design}

\begin{newrequirements}
    \begin{todolist}
    \item[\done] You should document the structural and 
        the behavioral aspects of your software 
        components. For projects that only use 
        embedded code (e.g., programming 
        microprocessor), a flow-chart 
        describing your software design could 
        be sufficient. Projects with user 
        interfaces may elaborate on the 
        functioning of the interface using some 
        of the models mentioned below. 

    \item The software components could be 
        documented using class diagram for the 
        whole system. While Class may be too 
        specific to JAVA or C++ environments, 
        you may use equivalent components 
        applicable to your design. For 
        instance, VI for LabVIEW designs, MDL 
        files in MATLAB, etc… If the model is 
        too big, partition the diagram using 
        some reasonable criteria.  For example, 
        you may provide the entity classes and 
        the controller classes as separate 
        diagrams. 

    \item Specific emphasis should be given to 
        the elaboration of the software 
        components that are responsible for 
        interfacing with the hardware 
        components of your design. For example, 
        if a protocol-like procedure was 
        developed in connecting to a hardware 
        module then it should be explained in 
        detail. Such components may include 
        packetization/depaketization 
        procedures, etc… 

    \item Wherever applicable, all associations 
        between classes/software-modules should 
        be identified through defining the 
        association name and the multiplicities 
        on both ends. Aggregation and 
        inheritance relationships should be 
        identified.  A brief explanation should 
        accompany each diagram. 

    \item[\done] Overall software logic may also be 
        described in order to know the 
        appropriate logic flow. In case of 
        LabVIEW or SIMULINK programs, this may 
        not be needed. For other programming 
        environments, the state diagram or 
        extended flow chart may be sufficient. 

    \item In case of graphical codes (such as 
        LabVIEW programs) the software 
        structure may be described by various 
        sub-Vis of the system. Similarly for 
        SYMLINK diagrams, the models should be 
        explained individually. The complete 
        program (graphical/text) should be 
        included in appendix and should not be 
        listed completely in this section. 
                
    \end{todolist}
\end{newrequirements}

\subsubsection{Simulation}
Based on the use case of this project, we first receive information
about the targets' count, distribution and mobility pattern and use
these pieces of
information to produce a file containing the weights for a \gls{drl}
model.
The simulation and \gls{rl} are critical
components to output this file thus achieving objective~\ref{obj:drl}.
The design for these components are shown in~\cref{fig:sim-flowchart}.

\begin{figure}[p]
    \centering
    \includegraphics[width=1.0\textwidth]{sim-flowchart}
    \caption{A flowchart showing the training process
        of the \gls{rl} in the project
        and the interactions between the libraries
        and programs.}
    \label{fig:sim-flowchart}
\end{figure}

In our framework, we have used the Parrot Sphinx simulator
as the environment and a simulated Anafi drone as the agent.
The simulated drone extends the OpenAI Gym \texttt{Env} 
Python class
to inherit the methods every RL agent
needs to undergo to learn.
The exchange of state, reward and action between them 
occur through the Parrot Olympe controller as well as
through JSON-RPC and message passing protocols.
More detailed commands used and steps taken are laid out 
in~\cref{fig:sim-flowchart}.

The Parrot Olympe library was used for sending movement commands to
the drone.
It allowed us to connect
to the simulated drone by specifying the drone's
\textsc{ip}. Once the connection was established, 
we could send the Olympe control commands to the drone
to execute the visitation task. 
Which command to use
depends on the \gls{rl} model.

The \gls{rl} was aided 
by another library called \gym.
We used it to facilitate developing the
\gls{drl} algorithm we are implementing and to 
teach the drone how to achieve the 
target visitation mission.
Specifically, \gym provides an abstract class 
called \texttt{Env}
which we have inherited and overridden the 
required methods.
One of the methods is step() which is contained in
\cref{fig:sim-flowchart}.

To train a drone using RL requires the
design of the environment, the agent itself and
the interaction between them as shown in~\cref{fig:rl}. 
The agent, due to being in a certain state, chooses and 
performs an action on
the environment resulting in the environment 
rewarding the agent for taking the action in that state
and then replying to it with a next state.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.8\textwidth]{rl-flowchart}
	\caption{The interaction between the agent and environment
        in \gls{rl} \cite{Sut20}.}
	\label{fig:rl}
\end{figure}

The action space of the agent is defined as a class, and its
elements call the necessary Olympe functions. 
The space consists of 9 movements: 
forward, backward, left,
right, forward-left, forward-right, backward-left,
backward-right and no-operation (hover).

We have set the reward to be equal to 1.5 multiplied by 
the number of new targets captured in the new state.
Each target is given a unique \textsc{id} which 
is embedded in the \textsc{qr} code that the targets are covered with
as shown in~\cref{fig:target}.
If there is no new target, the reward is -1. 
This ensures the drone learns to
minimise the time.
Since there are 10 targets, it follows that the maximum
return (sum of rewards in an episode) that the agent can gain  
in an episode is 
\begin{align}
        1.5 \times 10 = 15
\end{align}
To obtain the number of new targets, the drone's simulated camera is
used to take a photo of the cell
underneath, which is then processed by a \textsc{qr} code detection 
model, Pyzbar. 
The outputs of the processing are the \textsc{id}s of 
the detected targets, 
of which only the previously not encountered ones during 
the episode are counted towards the reward.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.8\textwidth]{target-3}
	\caption{Example of a target with ID 3 in the environment. The QR code
		embedding the ID information covers the top side of the target.}
	\label{fig:target}
\end{figure}

For the state space, the ground is divided into 25 cells as
illustrated in~\cref{fig:grid} with the numbers representing their
\textsc{id}s. 
In each timestep, the drone can occupy only one of these cells.
In addition to the cell \textsc{id}, the state space is made up of
other pieces of information as follows
\begin{align}
	s = \{ t, cell, [ I_1, I_2, I_3, \ldots, I_m] \} 
	\label{eq:state-space}
\end{align}

\noindent 
where $t$ is the current time step, $cell$ is the ID of the
cell underneath the drone, $I_k$ is the binary variable 
that indicates if the target with an ID of $k$ has been
visited, $m$ is the total number of targets,
and the vector of length $m$ is the container for the
$I$ indicators. 
For example,
if only targets with ID's 3 and 7 have been visited
in the current and previous time steps since the beginning of the 
episode,
then the vector will have elements of one for $I_3$ and $I_7$ while
the other elements are zeros.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.8\textwidth]{grid}
	\caption{The environment of the agent with its ground
		divided into 25 cells.}
	\label{fig:grid}
\end{figure}

\subsubsection{User Interface}

\lipsum[9]

\end{document}
